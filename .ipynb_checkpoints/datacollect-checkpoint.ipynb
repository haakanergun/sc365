{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2550ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import selenium\n",
    "from selenium import webdriver as wb\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from lxml import html\n",
    "import re\n",
    "from datetime import datetime, timedelta, date\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "from multiprocessing.dummy import Pool\n",
    "from multiprocessing import cpu_count\n",
    "import logging\n",
    "import io\n",
    "import traceback\n",
    "import winsound\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f941a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tables(url,s):\n",
    "    try:\n",
    "        parameter = f\"&tab=form_teams&cmp=1&lm={s}\"\n",
    "        r= requests.get(url+parameter)\n",
    "        soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "        stats =pd.read_html(url+parameter,flavor='lxml')\n",
    "        t1data = stats[2].T.reset_index(drop=True).iloc[0].append(stats[2].T.reset_index(drop=True).iloc[2]).reset_index(drop=True)\n",
    "        t1col = ('Home ' + stats[2].T.reset_index(drop=True).iloc[1]).append('Away ' + stats[2].T.reset_index(drop=True).iloc[1])\n",
    "        t2data = stats[3].T.reset_index(drop=True).iloc[0].append(stats[3].T.reset_index(drop=True).iloc[2]).reset_index(drop=True)\n",
    "        t2col = ('Home ' + stats[3].T.reset_index(drop=True).iloc[1]).append('Away ' + stats[3].T.reset_index(drop=True).iloc[1])\n",
    "        col = t1col.append(t2col)\n",
    "        datas = t1data.append(t2data).reset_index(drop=True)\n",
    "        df = pd.DataFrame(columns=col,data = np.array([datas])).add_prefix(f'{s}_')\n",
    "        return df\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def yarat(url):\n",
    "    try:\n",
    "        parameter = \"&tab=form_teams&cmp=0&lm=5\"\n",
    "        r= requests.get(url+parameter)\n",
    "        soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "        try:\n",
    "            evname = soup.find_all('div',{\"class\":\"live_game_ht\"})[0].text.replace('\\n','')\n",
    "        except:\n",
    "            evname = np.nan\n",
    "        try:\n",
    "            evid = soup.find_all('div',{\"class\":\"live_game_ht\"})[0].find('a')['href'].split('/')[-2]\n",
    "        except:\n",
    "            evid = np.nan\n",
    "        try:\n",
    "            depid = soup.find_all('div',{\"class\":\"live_game_at\"})[0].find('a')['href'].split('/')[-2]\n",
    "        except:\n",
    "            depid = np.nan\n",
    "        try:\n",
    "            depname = soup.find_all('div',{\"class\":\"live_game_at\"})[0].text.replace('\\n','')\n",
    "        except:\n",
    "            depname = np.nan\n",
    "        try:\n",
    "            evgoal = int(soup.find_all('div',{\"class\":\"live_game_goal\"})[0].text.replace('\\n',''))\n",
    "        except:\n",
    "            evgoal = np.nan\n",
    "        try:    \n",
    "            depgoal = int(soup.find_all('div',{\"class\":\"live_game_goal\"})[1].text.replace('\\n',''))\n",
    "        except:\n",
    "            depgoal = np.nan\n",
    "        try:\n",
    "            league = soup.find_all('div',{\"class\":\"breadcrumb\"})[0].find_all('a',href=True)[2]['href'].split('/')[-2]\n",
    "        except:\n",
    "            league = np.nan\n",
    "        try:\n",
    "            text = soup.find_all('div',{\"class\":\"block_header bkcenter\"})[0].text.strip('\\n')\n",
    "        except:\n",
    "            text = np.nan\n",
    "\n",
    "        data = {'Home Team':evname,'Home ID':evid,'Away Team':depname,'Away ID':depid,'Home Goal':evgoal,'Away Goal':depgoal,'League':league,'Text':text,\n",
    "\n",
    "    }\n",
    "        datas = pd.DataFrame()\n",
    "        for i in [1,2,3,4,5,10,15]:\n",
    "            datas = pd.concat([datas,tables(url,i)],axis=1)\n",
    "        return pd.concat([pd.DataFrame(data,index=[0]),datas],axis=1)\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "def hreftopla(url):\n",
    "    hrefs = []\n",
    "    start = 'http://soccer365.me'\n",
    "    r= requests.get(url)\n",
    "    soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "    for a in soup.find_all('a',class_='game_link',href=True):\n",
    "        hrefs.append(start +a['href'])\n",
    "    return hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8efd9af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home Team</th>\n",
       "      <th>Home ID</th>\n",
       "      <th>Away Team</th>\n",
       "      <th>Away ID</th>\n",
       "      <th>Home Goal</th>\n",
       "      <th>Away Goal</th>\n",
       "      <th>League</th>\n",
       "      <th>Text</th>\n",
       "      <th>1_Home Games</th>\n",
       "      <th>1_Home Wins</th>\n",
       "      <th>...</th>\n",
       "      <th>15_Away Corner</th>\n",
       "      <th>15_Away Corner (competitor)</th>\n",
       "      <th>15_Away Fouls</th>\n",
       "      <th>15_Away Fouls (competitor)</th>\n",
       "      <th>15_Away Offsides</th>\n",
       "      <th>15_Away Offsides (competitor)</th>\n",
       "      <th>15_Away Yellow cards</th>\n",
       "      <th>15_Away Yellow cards (competitor)</th>\n",
       "      <th>15_Away Red cards</th>\n",
       "      <th>15_Away Red cards (competitor)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slavia Prague</td>\n",
       "      <td>149</td>\n",
       "      <td>Legia</td>\n",
       "      <td>622</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>UEFA Europa League, play-off round, 19.08.2021...</td>\n",
       "      <td>1</td>\n",
       "      <td>100% 1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.13</td>\n",
       "      <td>11.87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Home Team Home ID Away Team Away ID  Home Goal  Away Goal League  \\\n",
       "0  Slavia Prague     149     Legia     622          2          2     20   \n",
       "\n",
       "                                                Text 1_Home Games 1_Home Wins  \\\n",
       "0  UEFA Europa League, play-off round, 19.08.2021...            1      100% 1   \n",
       "\n",
       "   ... 15_Away Corner 15_Away Corner (competitor) 15_Away Fouls  \\\n",
       "0  ...            5.0                        4.13         11.87   \n",
       "\n",
       "  15_Away Fouls (competitor) 15_Away Offsides 15_Away Offsides (competitor)  \\\n",
       "0                       15.0              1.0                          0.87   \n",
       "\n",
       "  15_Away Yellow cards 15_Away Yellow cards (competitor) 15_Away Red cards  \\\n",
       "0                  2.2                              2.13              0.13   \n",
       "\n",
       "  15_Away Red cards (competitor)  \n",
       "0                           0.13  \n",
       "\n",
       "[1 rows x 400 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yarat('http://soccer365.me/games/1619453/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf56876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt file to list\n",
    "with open('2000mac.txt', 'r') as f:\n",
    "    matchlinks = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e06ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436692"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matchlinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c81bee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://soccer365.me/games/1619453/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchlinks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89eb9b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqdm.threads import pqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5873ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "eskiveriler=pd.read_csv('train.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19632ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Başarılı Eklenen Veri 100 / 100\n",
      "46/2000 : 2.3%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e68abdb5ebc41ab89c0ad0672c24a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUBMITTING | :   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ee3f45eb2a4f82a73e409bf48400d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING | :   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eskiveriler=pd.read_csv('train.csv',index_col=[0])\n",
    "sonlen=0\n",
    "ilklen=0\n",
    "for i in range(0,2000):\n",
    "    sonlen = ilklen\n",
    "    ilklen = len(eskiveriler)\n",
    "    print(f'Başarılı Eklenen Veri {ilklen-sonlen} / {100}')\n",
    "    print(f'{i+1}/{2000} : {((i+1)/2000)*100}%')\n",
    "    maclardf = pd.concat(pqdm(matchlinks[i*100:(i+1)*100],yarat,n_jobs=24),ignore_index=True)\n",
    "    eskiveriler=eskiveriler.append(maclardf,ignore_index=True)\n",
    "    if i%10 == 0:\n",
    "        eskiveriler.to_csv('train.csv')\n",
    "    clear_output(wait=True)\n",
    "eskiveriler.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43f0660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eskiveriler.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac6d2c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce03efa94614b2780b6c2f2fc7c3d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SUBMITTING | :   0%|          | 0/764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae52b53c985d457e8f225ec3c791e7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING | :   0%|          | 0/764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998312838a704bbcb853422ccc8e8634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING | :   0%|          | 0/764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "maclardf = pd.concat(pqdm(merged[250*100:],yarat,n_jobs=24),ignore_index=True)\n",
    "eskiveriler=eskiveriler.append(maclardf,ignore_index=True)\n",
    "eskiveriler.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287e15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
